{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM & GRU for Stock Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import json, time, pickle\n",
    "from PIL import Image as PILImage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.express as px\n",
    "from alpha_vantage.timeseries import TimeSeries \n",
    "from IPython.display import Image, display, clear_output\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM, Dropout , GRU,Input,Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes, loads, helpers élémentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailies='1min, 5min, 15min, 30min, 60min'.split(', ')\n",
    "columns=[\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "models=dict()\n",
    "histories=dict()\n",
    "API_KEY=open(\"alpha_api_key.txt\",\"r\").read()\n",
    "companies_data = json.load(open('companies_list.txt'))\n",
    "companies_dict = {data[\"ticker\"]: (data[\"name\"], data[\"sector\"], data[\"industry\"]) for data in companies_data}\n",
    "def plot_col(df,col):\n",
    "    plt.figure(figsize=(16,3))\n",
    "    plt.plot(df.index,df[col])\n",
    "    plt.xlabel('Date')\n",
    "    xticks,labels=range(0,len(df),312),list(df.index)[::312]\n",
    "    plt.xticks(xticks,labels,rotation=30,fontsize=6)\n",
    "    plt.ylabel(col)\n",
    "    plt.title(f\"Plot of {col}\")\n",
    "    plt.show()\n",
    "\n",
    "def apply_split(df,date,value):\n",
    "    for col in ['open','high','low','close']:\n",
    "        df.loc[df.index < date, col] = df.loc[df.index < date, col] / value\n",
    "    df.loc[df.index < date, 'volume'] = df.loc[df.index < date, 'volume'] * value\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un callback pour l'arrêt des entrainements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patience(Callback):\n",
    "    def __init__(self, name,patience):\n",
    "        super().__init__()\n",
    "        self.name=name\n",
    "        self.patience=patience\n",
    "        self.min_val=float('inf')\n",
    "        self.turns_without_improvement=0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_loss = logs.get(self.name)\n",
    "        if current_loss is not None and current_loss < self.min_val:\n",
    "            self.min_val=current_loss\n",
    "            self.turns_without_improvement=0\n",
    "        else:\n",
    "            self.turns_without_improvement+=1\n",
    "        if self.turns_without_improvement>self.patience:\n",
    "            print(f\"\\nStopping training: loss did not decrease for {self.patience} epochs. Current {self.name}: {current_loss:.4f}\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Une classe \"Compagny\" : \n",
    "- ticker, interval (par défaut daily), name, sector, industry et dates\n",
    "- méthodes __repr__, __set_data__, __get_data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Company:\n",
    "    def __init__(self, ticker,interval='1D'):\n",
    "        self.ticker=ticker\n",
    "        self.interval=interval\n",
    "        self.name,self.sector,self.industry = companies_dict[ticker]\n",
    "        self.splits=yf.Ticker(self.ticker).splits\n",
    "        self.splits={k.strftime(\"%Y-%m-%d\"):v for k,v in self.splits.items()}\n",
    "        self.dates=None\n",
    "    def __repr__(self):\n",
    "        return f\"Company :{self.ticker} --> {self.name} ({self.sector}, {self.industry}, interval={self.interval})\"\n",
    "    def set_data(self):\n",
    "        \"\"\"period in '1d','w','1m', attention yfinance accès limité hors premium\"\"\"\n",
    "        if self.interval not in dailies+['1D','1M']:\n",
    "            print(f\"interval not correct, select one in {dailies+['1D','1M']}\")\n",
    "            return\n",
    "        file_name=f\"{self.ticker}_{self.interval}.csv\"\n",
    "        ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "        if self.interval in dailies:\n",
    "            data,metadata=ts.get_intraday(symbol=self.ticker, interval=self.interval,outputsize='full')\n",
    "        elif self.interval=='1D':\n",
    "            data,metadata=ts.get_daily(symbol=self.ticker, outputsize='full')\n",
    "        elif self.interval=='1M':\n",
    "            data,metadata=ts.get_monthly(symbol=self.ticker,outputsize='full')\n",
    "        data.columns=columns\n",
    "        data.index=data.index.strftime('%Y-%m-%d')\n",
    "        data=data.iloc[::-1]\n",
    "        for date in sorted(self.splits,reverse=True):\n",
    "            if data.index[0]<date and date<=data.index[-1]:\n",
    "                print(f\"Applying unsplit at date {date} with value {self.splits[date]}\")\n",
    "                data=apply_split(data,date,self.splits[date])\n",
    "        data.to_csv(file_name,index=True)\n",
    "        self.dates=list(data.index)\n",
    "        with open(f\"{self.ticker}_{self.interval}_metadata.json\", 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "    def get_data(self):\n",
    "        if self.interval not in dailies+['1D','1M']:\n",
    "            print(f\"interval not correct, select one in {dailies+['1D','1M']}\")\n",
    "            return None\n",
    "        file_name=f\"{self.ticker+'_'+self.interval}.csv\"\n",
    "        if file_name not in os.listdir():\n",
    "            self.set_data()\n",
    "        return pd.read_csv(file_name,index_col=0),json.load(open(f\"{self.ticker+'_'+self.interval}_metadata.json\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog=Company('GOOG')\n",
    "print(goog)\n",
    "goog.set_data()\n",
    "df,metadata=goog.get_data()\n",
    "print(f\"metadata={metadata}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_col(df,'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_col(df,'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des moyennes mobiles : 6,30,60,90 jours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W6 = df.rolling(window=6).mean()\n",
    "W30 = df.rolling(window=30).mean()\n",
    "W60 = df.rolling(window=60).mean()\n",
    "W90 = df.rolling(window=90).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "W6['close'][df.index>\"2022\"].plot(label='6 days rolling').autoscale(axis='x',tight=True)\n",
    "W30['close'][df.index>\"2022\"].plot(label='30 days rolling').autoscale(axis='x',tight=True)\n",
    "W60['close'][df.index>\"2022\"].plot(label='60 days rolling').autoscale(axis='x',tight=True)\n",
    "W90['close'][df.index>\"2022\"].plot(label='90 days rolling').autoscale(axis='x',tight=True)\n",
    "df['close'][df.index>\"2022\"].plot(label='Close Price',color='k',linestyle='-',linewidth=2).autoscale(axis='x',tight=True)\n",
    "plt.legend()\n",
    "plt.title('Moyennes mobiles depuis 2022',backgroundcolor='g',color='white',fontweight='bold')  \n",
    "plt.xlabel('Date',labelpad=15)\n",
    "plt.ylabel('Price',labelpad=15)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard scaling des données :\n",
    "!['Les scalers'](scalers.png )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "scaled_data=scaler.fit_transform(df)\n",
    "scaled=pd.DataFrame(scaled_data,columns=df.columns,index=df.index)\n",
    "scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split et préparation des données:\n",
    "On prépare les données en spécifiant la taille de fenêtre servant la mémoire du modèle (window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=round(len(scaled)*0.8)\n",
    "val_size=round(train_size*0.75)\n",
    "train,val,test_set=scaled[:val_size],scaled[val_size:train_size],scaled[train_size:]\n",
    "print(f\"train_size={val_size}, val_size={train_size-val_size}, test_size={len(scaled)-train_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_series_data(Data, window_size):\n",
    "    data_array = Data.values\n",
    "    sequences = np.array([data_array[i:i+window_size] for i in range(len(data_array) - window_size)])\n",
    "    labels = data_array[window_size:]\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=60\n",
    "X_all, y_all=prepare_time_series_data(scaled, window_size)\n",
    "X_train, y_train = prepare_time_series_data(train, window_size)\n",
    "X_val,y_val=prepare_time_series_data(val, window_size)\n",
    "X_test, y_test = prepare_time_series_data(test_set, window_size)\n",
    "print(f\"shapes : X_train: {X_train.shape}, y_train: {y_train.shape}, X_val: {X_val.shape}, y_val: {y_val.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\"X_all: {X_all.shape}, y_all: {y_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier modèle LSTM simple:\n",
    "- RNN + Dropout\n",
    "- deux couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM1 = Sequential()\n",
    "LSTM1.add(Input(shape=(window_size,X_train.shape[2])))\n",
    "LSTM1.add(LSTM(100,return_sequences=True))\n",
    "LSTM1.add(Dropout(0.2))\n",
    "LSTM1.add(LSTM(100,return_sequences=False))\n",
    "LSTM1.add(Dropout(0.2))\n",
    "LSTM1.add(Dense(X_train.shape[2]))\n",
    "LSTM1.compile(optimizer='adam', loss='mean_squared_error',metrics=['mean_absolute_error'])\n",
    "\n",
    "LSTM1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "early_stop=Patience('loss',3)\n",
    "histories['LSTM1'] = LSTM1.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stop],verbose=1)\n",
    "models['LSTM1'] = LSTM1\n",
    "clear_output()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in histories['LSTM1'].history.keys():\n",
    "    print(key,\" : \",histories[\"LSTM1\"].history[key][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=' Loss and Mean_absolute_error over Epochs '\n",
    "xlabel=' Epochs '\n",
    "LSTM1_losses = pd.DataFrame(LSTM1.history.history)\n",
    "ax = LSTM1_losses.plot(figsize=(10,6),title=title)\n",
    "ax.autoscale(axis='x',tight=True)\n",
    "ax.set(xlabel=xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM1_losses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_inverse_transform(DF,model,scaler,start=None, stop=None):\n",
    "    if start is None:start=0\n",
    "    if stop is None:stop=len(DF)\n",
    "    tranche=slice(start,stop,None)\n",
    "    test_set=X_all[tranche]\n",
    "    predictions = model.predict(test_set)\n",
    "    inverse_predictions = scaler.inverse_transform(predictions)\n",
    "    test_df = pd.DataFrame(inverse_predictions,columns=[col+'_pred' for col in DF.columns],index=DF.iloc[start+window_size:min(stop+window_size,len(df))].index)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_1_val = predict_and_inverse_transform(df, LSTM1, scaler,val_size,train_size)\n",
    "test_df_1_test = predict_and_inverse_transform(df, LSTM1, scaler,train_size,len(df))\n",
    "print(f\"len(test_df_1_val)={len(test_df_1_val)}, len(test_df_1_test)={len(test_df_1_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='high'\n",
    "col_index=df.columns.get_loc(col)\n",
    "indexes=df.index.to_list()\n",
    "start_plot_date=indexes[len(indexes)//2]\n",
    "start_index=indexes.index(start_plot_date)\n",
    "print(f\"start_index={start_index}\")\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(df.index[start_index:], df[col][start_index:], label='Observed', color='k')\n",
    "plt.plot(test_df_1_val.index, test_df_1_val[col+'_pred'], label='Predicted - Validation',color='g')\n",
    "plt.plot(test_df_1_test.index, test_df_1_test[col+'_pred'], label='Predicted - Test',color='m')\n",
    "plt.legend()\n",
    "plt.title(f\"Prédictions val et test de {col}  --> Impressionnant!\",backgroundcolor='b',alpha=0.5,color='white',fontweight='bold')  \n",
    "plt.xlabel('Date',labelpad=15)\n",
    "plt.ylabel('Price',labelpad=15)\n",
    "plt.xticks(df.index[start_index::312],rotation=30,fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deuxième LSTM :\n",
    "- trois couches LSTM avec Dropout\n",
    "- une couche dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2 = Sequential()\n",
    "\n",
    "# First LSTM layer\n",
    "LSTM2.add(Input(shape=(window_size,X_train.shape[2])))\n",
    "LSTM2.add(LSTM(150, return_sequences=True))\n",
    "LSTM2.add(Dropout(0.2))\n",
    "# Second LSTM layer\n",
    "LSTM2.add(LSTM(100, return_sequences=True))\n",
    "LSTM2.add(Dropout(0.2))\n",
    "# Third LSTM layer \n",
    "LSTM2.add(LSTM(100, return_sequences=False)) \n",
    "LSTM2.add(Dropout(0.2))\n",
    "# Final Prediction (one neuron per feature)\n",
    "LSTM2.add(Dense(units=50))\n",
    "LSTM2.add(Dense(units=5))\n",
    "LSTM2.add(Dense(X_train.shape[2]))\n",
    "\n",
    "LSTM2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mean_absolute_error'])\n",
    "LSTM2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "early_stop = early_stop=Patience('loss',3)\n",
    "histories['LSTM2'] = LSTM2.fit(X_train, y_train,epochs=30,validation_data=(X_val, y_val),batch_size = 32,callbacks=[early_stop],verbose=1)\n",
    "models['LSTM2'] = LSTM2\n",
    "clear_output()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_2_test = predict_and_inverse_transform(df, LSTM2, scaler,train_size,len(df))\n",
    "test_df_2_val = predict_and_inverse_transform(df, LSTM2, scaler,val_size,train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle GRU : \n",
    "- une couche GRU\n",
    "- une couche Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_Model = Sequential()\n",
    "GRU_Model.add(Input(shape=(window_size, X_train.shape[2])))\n",
    "GRU_Model.add(GRU(128, activation='tanh'))\n",
    "GRU_Model.add(Dense(X_train.shape[2]))\n",
    "GRU_Model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "GRU_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "early_stop = early_stop=Patience('loss',3)\n",
    "histories['GRU'] = GRU_Model.fit(X_train, y_train, epochs=30,validation_data=(X_val, y_val),batch_size = 32,callbacks=[early_stop],verbose=1)\n",
    "models['GRU'] = GRU_Model\n",
    "clear_output()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_3_test = predict_and_inverse_transform(df, GRU_Model, scaler,train_size,len(df))\n",
    "test_df_3_val = predict_and_inverse_transform(df, GRU_Model, scaler,val_size,train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectionnal GRU:\n",
    "- une couche Bidirectionnal sur GRU suivie de dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_bidirectional = Sequential()\n",
    "GRU_bidirectional.add(Input(shape=(window_size, X_train.shape[2])))\n",
    "GRU_bidirectional.add(Bidirectional(GRU(128, activation='tanh')))\n",
    "GRU_bidirectional.add(Dropout(0.2))\n",
    "GRU_bidirectional.add(Dense(X_train.shape[2]))\n",
    "\n",
    "GRU_bidirectional.compile(optimizer='adam', loss='mean_squared_error',metrics=['mean_absolute_error'])\n",
    "GRU_bidirectional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "early_stop =Patience('loss',3)\n",
    "histories['GRU_bidirectional'] = GRU_bidirectional.fit(X_train, y_train, epochs=30,validation_data=(X_val, y_val),batch_size = 32,callbacks=[early_stop],verbose=1)\n",
    "models['GRU_bidirectional'] = GRU_bidirectional\n",
    "clear_output()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_4_test = predict_and_inverse_transform(df, GRU_bidirectional, scaler,train_size,len(df))\n",
    "test_df_4_val = predict_and_inverse_transform(df, GRU_bidirectional, scaler,val_size,train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='close'\n",
    "col_index=df.columns.get_loc(col)\n",
    "indexes=df.index.to_list()\n",
    "start_plot_date=\"2013-06-25\"\n",
    "start_index=indexes[len(indexes)//2]\n",
    "print(f\"start_index={start_index}\")\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(df.index[len(indexes)//2:], df[col][start_index:], label='Obs', color='k')\n",
    "plt.plot(test_df_1_val.index, test_df_1_val[col+'_pred'], label='Pred - Val LSTM1',)\n",
    "plt.plot(test_df_1_test.index, test_df_1_test[col+'_pred'], label='Pred - Test LSTM1')\n",
    "plt.plot(test_df_2_val.index, test_df_2_val[col+'_pred'], label='Pred - Val LSTM2',)\n",
    "plt.plot(test_df_2_test.index, test_df_2_test[col+'_pred'], label='Pred - Test LSTM2')\n",
    "plt.plot(test_df_3_val.index, test_df_3_val[col+'_pred'], label='Pred - Val GRU',)\n",
    "plt.plot(test_df_3_test.index, test_df_3_test[col+'_pred'], label='Pred - Test GRU')\n",
    "plt.plot(test_df_4_val.index, test_df_4_val[col+'_pred'], label='Pred - Val GRU_bid')\n",
    "plt.plot(test_df_4_test.index, test_df_4_test[col+'_pred'], label='Pred - Test GRU_bid')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"Comparison of Actual and Predicted {col} Daily Prices for LSTM1, LSTM2 and GRU, on validation and test datasets\",\n",
    "          backgroundcolor='b',alpha=0.5,color='white',fontweight='bold')  \n",
    "plt.xlabel('Date',labelpad=15)\n",
    "plt.ylabel('Price',labelpad=15)\n",
    "plt.xticks(df.index[len(indexes)//2::312],rotation=30,fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in histories:\n",
    "    print(name)\n",
    "    for k,v in histories[name].history.items():\n",
    "        print(f\"k={k}, v={v[-1]}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['mean_absolute_error', 'loss', 'val_mean_absolute_error', 'val_loss']\n",
    "results={name:[histories[name].history[k][-1] for k in metrics] for name in histories}\n",
    "x = np.arange(len(metrics))  \n",
    "bar_width = 0.2\n",
    "plt.figure(figsize=(16,4))\n",
    "for i,(name,values) in enumerate(results.items()):\n",
    "    plt.bar(x+i*bar_width, values, bar_width, label=name,alpha=0.8)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Comparison of Models on Various Metrics')\n",
    "plt.xticks(x + bar_width * (len(results) - 1) / 2, metrics)  \n",
    "plt.legend(title=\"Models\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
